{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# IPD et Machine learning\n",
    "\n",
    "Auteur : Philippe Mathieu, CRISTAL Lab, SMAC Team, University of Lille, email : philippe.mathieu@univ-lille.fr\n",
    "\n",
    "Contributeurs : Louisa Fodil (CRISTAL/SMAC), Céline Petitpré (CRISTAL/SMAC)\n",
    "\n",
    "Creation : 18/01/2018\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Le Dilemme itéré du prisonnier permet d'exprimer une infinité de stratégies. Il est naturel de se demander laquelle est la meilleure ? Malheureusement il n'y a pas de stratégie meilleure dans l'absolu. On ne peut par exemple pas jouer optimalement contre `All_D` et `Spiteful`. Ceci est du au fait qu'il s'agit d'un jeu simultané, et qu'au premier coup, on ne connait pas encore son adversaire. Il faut donc choisir. Il y a par contre des stratégie plus \"robustes\" que d'autres, au sens où elles sont toujours efficaces dans des environnements variés.\n",
    "Les compétitions écologiques et les sous-classes sont des moyens de faire varier légèrement l'environnement.\n",
    "Reste maintenant à trouver de bonnes stratégies.\n",
    "Nous cherchons ici à savoir quels sont les outils qui nous permettent d'identifier de nouvelles stratégies robustes et notamment si les techniques d'Intelligence Artificielle peuvent nous être utiles pour les mettre en évidence.\n",
    "\n",
    "Dans ce notebook nous considérons comme acquis tous les outils précédemment créés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All about simultaneous games (class Game with getNash(), getPareto(), getDominantStrategies())\n",
    "%run ../src/Game.py\n",
    "\n",
    "# All about ipd (Meeting, Tournament and Ecological classes)\n",
    "%matplotlib inline\n",
    "%run ../src/ipd.py\n",
    "\n",
    "# All about strategies (getPeriodics(n), getMem(X,Y), getClassicals())\n",
    "%run ../src/strategies.py\n",
    "\n",
    "# How to use these modules ?\n",
    "\n",
    "# We focus here on the iterated prisoner's dilemma Game\n",
    "dip =[(3,3),(0,5),(5,0),(1,1)]\n",
    "g = Game.Game(dip,['C','D'])\n",
    "\n",
    "# A tournament\n",
    "bag = []\n",
    "bag.append(Periodic('C'))\n",
    "bag.append(Periodic('D'))\n",
    "bag.append(Periodic('DDC'))\n",
    "bag.append(Periodic('CCD'))\n",
    "t=Tournament(g,bag,10)\n",
    "t.run()\n",
    "print(\"The matrix of scores of the tournament : \")\n",
    "print(t.matrix)\n",
    "print(\"One (if many) of the winner of the tournament: \")\n",
    "print(list(t.matrix.columns)[0])\n",
    "\n",
    "\n",
    "# An ecological competition\n",
    "eco = Ecological(g, [Periodic(\"C\",\"All_C\"), Periodic(\"D\",\"All_D\")])\n",
    "eco.run()\n",
    "print(\"Population evolution of the ecological competition : \")\n",
    "eco.drawPlot()\n",
    "print(\"One (if many) of the winner of the ecological competition : \")\n",
    "print(eco.historic.iloc[-1][0:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methode de Monte-Carlo\n",
    "\n",
    "## Battre une classe mem\n",
    "Il est très souvent (toujours ?) possible de trouver une stratégie capable de battre toutes celles d'une classe donnée dans une classe d'ordre supérieur. Par exemple trouver une `Mem(2,2)` capable de gagner dans l'ensemble des `Mem(1,1)`. La manière la plus simple d'en trouver une consiste à calculer un certain nombre de fois un génotype aléatoire d'une `Mem(2,2)`, de l'évaluer dans `Mem(1,1)`, de regarder son classement et de ne la conserver que si c'est la meilleure actuellement connue. C'est ce que l'on appelle une méthode de Monté-Carlo car elle teste des stratégies par pur hasard, comme à la roulette. \n",
    "Ce genre de méthode permet néanmoins d'en trouver comme par exemple `Mem(2,2,'CCCCDDDCCDCDDDDDDD')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindBest:\n",
    "    def __init__(self, game):\n",
    "        self.game = game\n",
    "\n",
    "    def generate_random_genotype(self, x, y):\n",
    "        \"\"\"\n",
    "        Generates a random genotype from Mem(x,y)\n",
    "        \"\"\"\n",
    "        N = max(x,y) + 2**(x+y)\n",
    "        genotype = \"\"\n",
    "        for i in range (N):\n",
    "            genotype += random.choice(self.game.actions)\n",
    "        return genotype\n",
    "\n",
    "    def random_selection(self, x, y, nb_tests, soupe):\n",
    "        \"\"\"\n",
    "        Does nb_tests ecological competitions against soupe with each time a random genotype from Mem(x,y) \n",
    "        Returns a sorted list of the genotypes based on their rank in the ecological competition\n",
    "        \"\"\"\n",
    "        d = dict()\n",
    "        for n in range(nb_tests):\n",
    "            genotype = self.generate_random_genotype(x,y)\n",
    "            strat = Mem(x,y,genotype)\n",
    "            eco = Ecological(self.game, soupe+[strat])\n",
    "            eco.run()\n",
    "            d[genotype] = eco.historic.columns.tolist().index(strat.name)\n",
    "        return sorted(d.items(), key=lambda t: t[1])\n",
    "\n",
    "\n",
    "gen = FindBest(g)\n",
    "soupe = getMem(1,1)\n",
    "# Prints the two best genotypes frome the Mem(2,2) against soupe and after 10 executions\n",
    "print(gen.random_selection(2,2, 10,soupe)[1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation de la stratégie trouvée précédemment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag3=getMem(1,1)\n",
    "e2=Ecological(g,bag3+[Mem(2,2,'CCCCDDDCCDCDDDDDDD')])\n",
    "e2.run()\n",
    "e2.drawPlot(None,4)\n",
    "evol=e2.historic\n",
    "print(evol.iloc[-1][evol.iloc[-1]>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo Génétique\n",
    "\n",
    "Les techniques de Monte-Carlo sont simples à comprendre mais lentes à converger. Les algorithmes génétiques sont bien plus performants pour ce type de recherche. Python offre pour ce type d'algorithme, des librairies assez performantes. C'est le cas de la librairie [Deap](https://deap.readthedocs.io/en/master/).\n",
    "\n",
    "Un algo génétique a pour objectif de trouver un bon génotype dans un ensemble des phénotypes possible. Il démarre initialement d'une liste de taille fixée, d'individus pris au hasard. Il effectue plusieurs tours de calculs à partir de cette liste. A chaque tour, il élimine de la liste les individus les plus mauvais calculés selon une fonction de fitness  qu'il faut préciser( ici `evaluateInd`). Il complète alors sa liste avec de nouveaux individus obtenus à l'aide de deux opérations élémentaires : la mutation qu'il faut aussi préciser ici (`myMutation`) et le crossing over (`cxTwoPoint` (déjà définie dans deap)) pour toujours avoir une liste de même taille.\n",
    "\n",
    "Ci dessous nous définissons une classe Genetic qui s'appuie sur Deap et qui définit la Mutation sur des génotypes de type `mem(x,y)`. On définit aussi notre propre fonction de fitness basée sur le résultat du classement de la stratégie dans june compétition écologique.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from deap import creator, base, tools, algorithms\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "class Genetic:\n",
    "\n",
    "    def __init__(self, game, x, y, soupe, option = \"tournament\", length = 100):\n",
    "        self.game = game\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.soupe = soupe\n",
    "        self.option = option\n",
    "        self.length = length\n",
    "\n",
    "\n",
    "    def createEnv(self):\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(-1.0,)) #-1.0 in order to minimize , 1.0 to maximize\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        toolbox = base.Toolbox()\n",
    "        toolbox.register(\"random_action\", random.choice, \"CD\")\n",
    "        DIM = max(self.x,self.y) + 2**(self.x+self.y)\n",
    "        toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.random_action, n=DIM)\n",
    "        toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "        toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "        toolbox.register(\"select\", tools.selBest)\n",
    "        if self.option == \"tournament\" : \n",
    "            toolbox.register(\"evaluate\", self.evaluateIndTournament)\n",
    "        elif self.option == \"ecological\":\n",
    "            toolbox.register(\"evaluate\", self.evaluateIndEcological)        \n",
    "        toolbox.register(\"mutate\", self.myMutation)\n",
    "        return toolbox\n",
    "\n",
    "\n",
    "    \n",
    "    def runEvolutionnary(self, toolbox, pop, parents, children, cxpb, mutpb):\n",
    "        \"\"\"\n",
    "        pop : number of individuals in the population \n",
    "        parents : The number of individuals to select for the next generation.\n",
    "        children : The number of children to produce at each generation.\n",
    "        cxpb : The probability that an offspring is produced by crossover.\n",
    "        mutpb : The probability that an offspring is produced by mutation.\n",
    "        \"\"\"\n",
    "        # The number of generation.\n",
    "        ngen = 1\n",
    "        pop = toolbox.population(n=pop)\n",
    "        fit = math.inf\n",
    "        # The algo stops when one individual becomes first in the ranking \n",
    "        while (fit > 1):\n",
    "            algorithms.eaMuPlusLambda(pop, toolbox, parents, children, cxpb, mutpb, ngen)\n",
    "            top = sorted(pop, key=lambda x:x.fitness.values[0])[-1]\n",
    "            fit = top.fitness.values[0]\n",
    "            print('Ranking : '+str(int(fit)))\n",
    "        print('Winning strategy : '+self.__str__(top))\n",
    "        return self.__str__(top)\n",
    "\n",
    "\n",
    "    def __str__(self,individual):\n",
    "        s = \"\"\n",
    "        for i in range(len(individual)):\n",
    "            s += individual[i]\n",
    "        return s\n",
    "\n",
    "\n",
    "    def evaluateIndEcological(self, individual):\n",
    "        \"\"\"\n",
    "        Evaluates an individual in an ecological competition\n",
    "        \"\"\"\n",
    "        genotype = self.__str__(individual)\n",
    "        strat = Mem(self.x, self.y, genotype)\n",
    "        eco = Ecological(self.game, self.soupe+[strat],  length=self.length)\n",
    "        eco.run()\n",
    "        return (float(eco.historic.columns.tolist().index(strat.name)+1),)\n",
    "    \n",
    "    def evaluateIndTournament(self, individual):\n",
    "        \"\"\"\n",
    "        Evaluates an individual in a tournament\n",
    "        \"\"\"\n",
    "        genotype = self.__str__(individual)\n",
    "        strat = Mem(self.x, self.y, genotype)\n",
    "        tournament = Tournament(self.game, self.soupe + [strat], self.length)\n",
    "        tournament.run()\n",
    "        return (float(tournament.matrix['Total'].tolist().index(tournament.matrix['Total'][strat.name])+1),)\n",
    "\n",
    "\n",
    "    def myMutation(self, individual):\n",
    "        \"\"\"\n",
    "        Mutates an individual in one random place\n",
    "        \"\"\"\n",
    "        i = random.randint(0, len(individual) - 1)\n",
    "        if individual[i] == 'C':\n",
    "            individual[i] = 'D'\n",
    "        else :\n",
    "            individual[i] = 'C'\n",
    "        return (individual,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les algorithmes génétiques appliquées aux compétitions écologiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un exemple simple et rapide : trouver parmi Mem(1,2) une stratégie qui gagne contre le triplet (All_C, All_D, TFT) en compétition écologique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = [Periodic(\"C\"),Periodic(\"D\"), Tft()]\n",
    "gen = Genetic(g,1,2,soup, \"ecological\", 100)\n",
    "toolbox = gen.createEnv()\n",
    "t = time.time()\n",
    "winner = gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n",
    "t2 = time.time()\n",
    "print(\"Execution time : \" + str(t2-t) + \" secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On peut maintenant vérifier avec un graphe que la stratégie est bien gagnante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Ecological(g, soup+[Mem(1,2,winner)], length = 100)\n",
    "e.run()\n",
    "e.drawPlot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(1,2) qui bat toutes les stratégies de Mem(1,1) (execution > 4H)\n",
    "Par exemple Mem(1,2,\"CCCCDDDDDD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,1,2,soup, \"ecological\", 100)\n",
    "toolbox = gen.createEnv()\n",
    "t = time.time()\n",
    "gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n",
    "t2 = time.time()\n",
    "print(\"Execution time : \" + str(t2-t) + \" secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici je vérifie et montre le résultat de l'algorithme génétique car l'algorithme génétique prends beaucoup de temps\n",
    "soup = getMem(1,1)\n",
    "e = Ecological(g, soup+[Mem(1,2,\"CCCCDDDDDD\")], length = 100)\n",
    "e.run()\n",
    "e.drawPlot(None,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(2,1) qui bat toutes les stratégies de Mem(1,1)(execution > 4H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,2,1,soup, \"ecological\", 100)\n",
    "toolbox = gen.createEnv()\n",
    "t = time.time()\n",
    "gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n",
    "t2 = time.time()\n",
    "print(\"Execution time : \" + str(t2-t) + \" secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici je vérifie et montre le résultat de l'algorithme génétique car l'algorithme génétique prends beaucoup de temps\n",
    "soup = getMem(1,1)\n",
    "e = Ecological(g, soup+[Mem(2,1,\"CCCDDDCDDD\")], 100)\n",
    "e.run()\n",
    "e.drawPlot(None,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(2,2) qui bat toutes les stratégies de Mem(1,1)(execution > 24H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,2,2,soup, \"ecological\", 100)\n",
    "toolbox = gen.createEnv()\n",
    "t = time.time()\n",
    "gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n",
    "t2 = time.time()\n",
    "print(\"Execution time : \" + str(t2-t) + \" secondes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ici je vérifie et montre le résultat de l'algorithme génétique car l'algorithme génétique prends beaucoup de temps\n",
    "soup = getMem(1,1)\n",
    "e = Ecological(g, soup+[Mem(2,2,\"CCCCDDDDDCDDDDDDCD\")], 100)\n",
    "e.run()\n",
    "e.drawPlot(None,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encore une fois les stratégies trouvées pour surperformer contre une classe donnée sont particulièrement bien adaptées à cette classe mais très peu robustes. En changeant ne serait-ce qu'une stratégie dans l'ensemble initiale, elles ne surperforment plus.\n",
    "On étudie ici une stratégie obtenue par algorithme génétique face à toutes les sous-classes de taille (n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On cherche une stratégie gagnante dans Mem(1,1) qui bat gentille, méchante et softmajority, hardmajority, periodic(\"DDC\") et periodic(\"ddcd\").\n",
    "soup = [Periodic(\"C\"),Periodic(\"D\"), SoftMajority(), HardMajority(), Periodic(\"DDC\"), Periodic(\"DDCD\")]\n",
    "gen = Genetic(g,1,1,soup, \"ecological\", 100)\n",
    "toolbox = gen.createEnv()\n",
    "gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# On regarde le classement de la stratégie gagnante trouvée dans les sous-classes de taile n-1.\n",
    "res = subClassesWithOneStrat(soup, 2, Mem(1,1,winner), length = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit ici que la stratégie gagnante a une pire place égale à 3, ce qui montre bien qu'elle ne gagne pas tout le temps.\n",
    "On a fait de l'\"overfitting\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les algorithmes génétiques appliquées aux tournois\n",
    "Les tournois permettent d'avoir des résultats beaucoup plus rapidement qu'avec les compétitions écologiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(1,2) qui bat toutes les stratégies de Mem(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,1,2,soup, \"tournament\", 100)\n",
    "toolbox = gen.createEnv()\n",
    "t = time.time()\n",
    "gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n",
    "t2 = time.time()\n",
    "print(\"Execution time : \" + str(t2-t) + \" secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(2,1) qui bat toutes les stratégies de Mem(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,2,1,soup, \"tournament\", 10)\n",
    "toolbox = gen.createEnv()\n",
    "t = time.time()\n",
    "gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)\n",
    "t2 = time.time()\n",
    "print(\"Execution time : \" + str(t2-t) + \" secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(2,2) qui bat toutes les stratégies de Mem(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,2,2,soup, \"tournament\", 10)\n",
    "toolbox = gen.createEnv()\n",
    "winner = gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trouver la meilleure stratégie Mem(3,3) qui bat toutes les stratégies de Mem(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = getMem(1,1)\n",
    "gen = Genetic(g,3,3,soup, \"tournament\", 10)\n",
    "toolbox = gen.createEnv()\n",
    "winner = gen.runEvolutionnary(toolbox, 25, 18, 7, 0.8, 0.015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier que cette stratégie est bien gagnante dans un tournoi avec les Mem(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=Tournament(g,soup+[Mem(3,3,winner)],10)\n",
    "t.run()\n",
    "print(\"The matrix of the tournament: \")\n",
    "print(t.matrix['Total'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approche neuronale (Caffe ? TensorFlow ? Keras ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliographie\n",
    "\n",
    "- Robert Axelrod, The Evolution of Cooperation (New York: Basic Books, 1984).\n",
    "- JP Delahaye et P Mathieu. Des surprises dans le monde de la coopération. Pour la Science, numéro spécial \"Les mathématiques sociales\", pp 58-66, Juillet 1999.\n",
    "- Philippe Mathieu, Jean-Paul Delahaye. [New Winning Strategies for the Iterated Prisoner's Dilemma](http://jasss.soc.surrey.ac.uk/20/4/12.html). J. Artificial Societies and Social Simulation 20(4) (2017)\n",
    "- Philippe Mathieu, Jean-Paul Delahaye. New Winning Strategies for the Iterated Prisoner's Dilemma. AAMAS 2015: 1665-1666\n",
    "- Bruno Beaufils, Jean-Paul Delahaye et Philippe Mathieu. Our Meeting with Gradual : A good Strategy for the Itareted Prisoner’s Dilemma, in Intern. Cof. on Artificial Life V (ALIFE V), pp. 159- 165, 16-18 mai 1996, Nara (Japon).\n",
    "- Martin Nowak et K. Sigmund, TIT for TAT in Heterogeneous Populations, Nature, vol. 355, n° 16, pp. 250-253, janvier 1992."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
