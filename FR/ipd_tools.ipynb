{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/game.py\n",
    "%run ../src/ipd.py\n",
    "%run ../src/strategies.py\n",
    "%run ../src/tools.py\n",
    "dip =[(3,3),(0,5),(5,0),(1,1)]   # Dilemme du prisonnier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation par synthèse de sous-classes\n",
    "\n",
    "Les compétitions écologiques offrent un outil de mesure assez fiable de la robustesse d'une stratégies, mais encore insuffisant. Il se peut par exemple que certaines stratégies se sacrifient pour d'autres dans un schema *maitre-esclave*. Avoir une synthèse de centaines voir de milliers de compétitions écologiques dans lesquelles on a enlevé certaines stratégies mesure sans doute une meilleure robustesse. L'une des idées les plus simples consiste à calculer les n compétitions possibles que l'on peut faire en enlevant 1 stratégie à un ensemble de n stratégies. On appelle cette technique la technique des sous-classes.\n",
    "Nous définissions ici 3 fonctions permettant de réaliser ces sous-classes.\n",
    "- `subclasses(bag, n)` qui évalue tous les sous ensembles possibles de taille n dans la bage\n",
    "- `subclassesWithOneStrat(bag, n, strat)` qui évalue Strat dans tous les sous ensembles possibles de taille n dans le `bag` en ajoutant systématiquement la stratégie `strat`\n",
    "- `subclassesRandomWithOneStrat(p, bag, n, Strat)` qui réalise p competitions de n strategies choisies au hasard dans la bage dans lesquelles on rajoute systématiquement Strat\n",
    "\n",
    "Les évaluations réalisées dans ces fonctions sont des compétitions écologiques.\n",
    "\n",
    "Ces fonctions renvoient à la fin un tableau avec pour chaque stratégie, sa meilleure place, sa pire place, sa moyenne et son écart-type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un cas simple : toutes les compétitions de 3 stratégies parmi les classiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_C = Periodic('C')\n",
    "All_D = Periodic('D')\n",
    "bag = [All_C, All_D, Tft(), Spiteful(), Gradual(), SoftMajority(), HardMajority()]\n",
    "subClasses(bag, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Un cas plus volumineux : toutes les stratégies Mem(1,1) avec une stratégie en moins à chaque fois\n",
    "Sachant qu'il y a 32 `mem(1,1)` cette opération réalise donc 32 compétitions de 31 stratégie. Notez que dans le cas de cette méthode, toutes les stratégies sont présentes (et absentes) exactement le même nombre de fois.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "before = time.time()\n",
    "bag = getAllMemory(1,1)\n",
    "subClasses(bag, len(bag)-1)\n",
    "after = time.time()\n",
    "print(\"Time : {}\".format(after-before))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test de la stratégie Spiteful avec tous les triplets de classiques\n",
    "Dans les cas des deux méthodes `subClassesWithOneStrat` seule la stratégie passée en paramètre participe à toutes les sous-classes (faisable pour des ensembles pas trop volumineux genre `mem(1,1)`). Dans la première elle participe à la totalité des sous-classes tandis qu'avec `subClassesRandomWithOneStrat` elle participe à un nombre fixé de sous classes de même taille mais prises aléatoirement (utilisable dans de gros ensembles comme `mem(2,2)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_C = Periodic('C')\n",
    "All_D = Periodic('D')\n",
    "bag = [All_C, All_D, Tft(), Gradual(), SoftMajority(), HardMajority()]\n",
    "res  = subClassesWithOneStrat(bag, 3, Spiteful())\n",
    "#Pour afficher le tableau en entier : \n",
    "#res = subClassesWithOneStrat(bag, 3, Spiteful(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est à noter que les objets `subClassesWithOneStrat` et `subClassesRandomWithOneStrat` conservent le \n",
    "meilleur et le pire des tournois pour la stratégie `strat`\n",
    "Au moment de l'affichage du classement des sous-classes il est de ce fait possible d'afficher l'ensemble de stratégies qui a été favorable ou défavorable à la stratégie `Strat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meilleureComp, pireComp, strategy = res\n",
    "print(\"La meilleure competition pour la stratégie \"+strategy.name +\" est : \")\n",
    "for strat in meilleureComp :\n",
    "    print(strat.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100 experiences de 10 stratégies prise au hasard dans mem(2,2) contre Gradual()\n",
    "Pour les `subclassesRandom`, si une stratégie n'a joué qu'une seule fois alors elle n'a pas d'écart-type (`NaN`); si elle n'a pas joué du tout alors toutes ses valeurs sont à `NaN` dans le tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = getAllMemory(2,2)\n",
    "res = subClassesRandomWithOneStrat(100,bag, 10, Gradual())\n",
    "#Pour afficher le tableau en entier : \n",
    "#subClassesRandomWithOneStrat(100, bag, 10, Gradual(), True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut d'ailleurs vérifier la compétition la plus \"défavorable\" à Gradual \n",
    "(comme c'est un choix aléatoire, donc 2 éxécutions ne donneront pas systématiquement le même résultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestComp, worstComp, strategy = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = worstComp\n",
    "e2=Ecological(g,bag)\n",
    "e2.run()\n",
    "e2.drawPlot(None,None)\n",
    "evol=e2.historic\n",
    "print(evol.iloc[-1])\n",
    "print(e2.historic.iloc[e2.generation].rank(0, method=\"min\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conception d'une méta-stratégie\n",
    "\n",
    "Une méta-stratégie est une stratégie composée de plusieurs stratégies. \n",
    "Dans un premier temps, chaque sous-stratégie joue pendant n tours puis on comptabilise le nombre de points obtenu par ces sous-stratégies pendant ces n tours.\n",
    "On choisit ensuite pour les `n` tours suivants, la stratégie qui a obtenu le plus de points sur cette période. On recommence la même procédure de choix d'une souss-stratégie tous les multiples de `n`.\n",
    "\n",
    "La classe `MetaStrategy(liste des stratégies, n)` permet de définir un tel fonctionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of MetaStrategy : the two results should be the same\n",
    "\n",
    "# with Metastrat\n",
    "metaStrat = MetaStrategy([Tft()], 5)\n",
    "bag = getMem(1,1)\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat)\n",
    "\n",
    "# without Metastrat\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, Tft())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check of MetaStrategy : the two results should be the same (with a Periodic)\n",
    "\n",
    "metaStrat = MetaStrategy([Periodic(\"CCD\")], 5)\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat)\n",
    "\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, Periodic(\"CCD\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests de méta-stratégies\n",
    "Grâce à cet outil il est alors possible de chercher à concevoir la meilleure meta-stratégie contre Memory(1,1) + Gradual.\n",
    "On réalise pour cela différents tests durant lesquels on change : \n",
    "- les stratégies\n",
    "- le nombre de tours n.\n",
    "\n",
    "Afin d'assurer un certaine robustesse, on peut utiliser le calcul de sous-classes `subClassesWithOneStrat` qui, pour une stratégie particulière (ici, notre meta-stratégie) fait plusieurs compétitions écologiques et mesure le meilleur rang, le pire rang, le rang moyen, et l'écart-type qu'elle obtient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaStrat = MetaStrategy([Tft(), Periodic(\"C\"), Spiteful(), Periodic(\"CCD\")], 5)\n",
    "bag = getMem(1,1)+[Gradual()]\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaStrat = MetaStrategy([Tft(), Periodic(\"C\"), Spiteful(), Periodic(\"CCD\")], 4)\n",
    "bag = getMem(1,1)+[Gradual()]\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaStrat = MetaStrategy([Tft(), Periodic(\"C\"), Spiteful(), Periodic(\"CCD\")], 3)\n",
    "bag = getMem(1,1)+[Gradual()]\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaStrat = MetaStrategy([Tft(), Periodic(\"C\"), Spiteful(), Periodic(\"CCD\")], 2)\n",
    "bag = getMem(1,1)+[Gradual()]\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaStrat = MetaStrategy([Tft(), Periodic(\"C\"), Spiteful(), Periodic(\"CCD\")], 1)\n",
    "bag = getMem(1,1)+[Gradual()]\n",
    "\n",
    "# Test avec les sous-classes\n",
    "# res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)\n",
    "\n",
    "# Test avec un tournoi\n",
    "# t = Tournament(g,[metaStrat]+bag)\n",
    "# t.run()\n",
    "# print(t.matrix)\n",
    "# print(t.matrix['Total'])\n",
    "\n",
    "# Test avec une competition écolo\n",
    "e = Ecological(g,[metaStrat]+bag)\n",
    "e.run()\n",
    "e.drawPlot(None,10)\n",
    "#print(e.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaStrat = MetaStrategy([Tft(), Spiteful(), Gradual()], 3)\n",
    "bag = getMem(1,1)+[Gradual()]\n",
    "res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate ici que la meilleure méta-stratégie que l'on arrive à concevoir est la Méta-stratégie composée des stratégies Tft(), Periodic('C'), Spiteful(), Periodic('CCD') avec un n=2 ou n=1.\n",
    "Verifions maintenant si cette séquence de stratégies est optimal en testant toutes les séquences possibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = getMem(1,1)+[Gradual()]\n",
    "all = itertools.permutations([Tft(), Periodic(\"C\"), Spiteful(), Periodic(\"CCD\")])\n",
    "for a in all : \n",
    "    print(\"Ordre\")\n",
    "    for strat in a : \n",
    "        print(strat.name)\n",
    "    metaStrat = MetaStrategy(a, 2)\n",
    "    res  = subClassesWithOneStrat(bag,len(bag)-1, metaStrat, length = 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après cette vérification les séquences de stratégies qui fournissent les moins bons résultats sont les séquences commençant par Periodic('CCD'), toutes les autres fournissent un meilleur résultat.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests d'équivalence de stratégies\n",
    "\n",
    "Les ensembles de stratégies que nous traitons sont parfois redondants : il contiennent les mêmes stratégies écrites de différentes manières. Il semble donc interessant de pouvoir simplifier des ensembles de stratégies en suprimant les doublons qu'ils peuvent contenir. \n",
    "Malheureusement, chacun le sait depuis Turing, l'équivalence de deux programmes est indécidable. Il n'y a donc pas de test parfait. Il est néanmoins possible de fournir des outils permettant d'avancer dans ce problème de simplification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour savoir si deux stratégies sont différentes, il suffit de les faire jouer contre une stratégie de référence et s'assurer qu'elles jouent différemment face à cet adversaire. Evidemment selon la complexité de cette stratégie de référence, le test est plus ou moins efficace. Si les stratégies jouent la même chose, cela ne fournit néanmoins pas une preuve de leur équivalence. Ce test est semi-décidable : si les stratégies jouent différemment il est sûr qu'elles sont différentes, mais si elles jouent de manière identique, c'est peut-etre que la stratégie de référence n'a pas sû révéler leur différence de comportement.\n",
    "La fonction `testEquivUnit` réalise ce test. On lui passe un couple de stratégies à tester et une stratégie de référence `opponent`, et elle compare ces deux stratégies durant `length` tours d'un meeting. Elle renvoie un booléen : équivalent (avec doute) ou pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testEquivUnit(strategies, opponent, length):\n",
    "    res = []\n",
    "    for strat in strategies :\n",
    "        m = Meeting(g, strat, opponent, length)\n",
    "        m.run()\n",
    "        res += [' '.join(map(str, m.s1_rounds)) ] \n",
    "    return len(set(res)) == 1\n",
    "\n",
    "\n",
    "print(testEquivUnit((Tft(), Spiteful())  , Periodic(\"CCDCD\"), 100))\n",
    "print(testEquivUnit((Tft(), Mem(0,1,\"cCD\")),  Periodic(\"CCDCD\"), 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1\n",
    "\n",
    "Deux stratégies peuvent bien évidemment obtenir le même score face à un adversaire commun,tout en ayant joué des coups différents. Pouvez vous identifier un tel cas ? On pourra utiliser le package itertools qui permet facilement de prendre 3 stratégies parmi n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le choix de la stratégie de référence est capital. Si elle est trop \"faible\", elle ne permet pas aux deux stratégies comparées de se \"révéler\" et indique alors qu'elles sont équivalentes alors qu'elles ne le sont pas, comme ci-dessous : Tft et Spiteful sont clairement différentes, et pourtant, face à All_C elles ont le même comportement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEquivUnit((Tft(), Spiteful()), Periodic('C'), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un test plus robuste pourrait être de les faire jouer contre `Periodic('CCD')`. Cette dernière permet à Tft et Spiteful de révéler leeur véritable comportement. On a cette fois ci la preuve que ces deux stratégies ne sont pas équivalentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testEquivUnit((Tft(), Spiteful()), Periodic('CD'), 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'améliorer cette comparaison de deux stratégies, il est préférable de les comparer non pas à une seule stratégie de référence, mais à un ensemble de stratégies de référence. On compare nos deux stratégies contre chaque élément de cet ensemble, ce qui constitue un test surement plus robuste. Bien évidemment dès que l'une de celles-ci indique une différence entre deux 2 stratégies, le test peut s'arrêter.\n",
    "La fonction `testEquivMultiple` fonctionne comme précédemment, mais cette fois en cherchant à trouver une différence de comportement grâce à une liste d'opposants. Comme précédemmnt elle renvoie un booléen : équivalent (avec doute) ou pas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testEquivMultiple(strategies, opponents, length):\n",
    "    for opponent in opponents : \n",
    "        equiv = testEquivUnit(strategies, opponent, length)\n",
    "        if equiv == False :\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "testEquivMultiple((Tft(), Spiteful()),[Periodic('CDCCDDC'), Periodic('DDCDCDD')], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour simplifier un ensemble de stratégies, il suffit maintenant d'effectuer le test précédent sur tous les couples possibles. Les stratégies identifiées comme potentiellement équivalentes sont alors regroupées.\n",
    "la fonction `classesEquiv(l, opponents, length)` effectue ce test sur l'ensemble `l`. Elle renvoie dans un dictionnaire les classes d'équivalence identifiées.\n",
    "Par exemple si on a strat1 équivalente à strat2 ainsi que strat3 qui elle n'a pas d'équivalente, la fonction va renvoyer un dictionnaire : `{strat1 : [strat2] , strat3 : []}`\n",
    "\n",
    "L'ensemble des clés de ce disctionnaire constitue l'ensemble de stratégies simplifié, et chaque entrée du dictionnaire correspond à un ensemble de stratégies équivalentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classesEquiv(l, opponents, length):\n",
    "    m = dict()\n",
    "    while len(l) > 0 :\n",
    "        m[l[0]] = []\n",
    "        ind = [0]\n",
    "        for j in range(len(l[1:])):\n",
    "            if testEquivMultiple([l[0], l[j + 1]], opponents, length):\n",
    "                m[l[0]] += [l[j + 1]]\n",
    "                ind += [j + 1]\n",
    "        ltmp = []\n",
    "        for i in range(len(l)):\n",
    "            if i not in ind :\n",
    "                ltmp += [l[i]]\n",
    "        l = ltmp\n",
    "    return m\n",
    "\n",
    "\n",
    "# This function allows you to display the names of the strategies instead of the instance number.\n",
    "def printCe(ce):\n",
    "    for key in ce.keys() :\n",
    "        if len(ce[key]) > 0:\n",
    "            print(\"\\n\" + key.name + \" : \" , end =\" \" )\n",
    "        #else :\n",
    "            # print(\"\\n\"+ key.name + \": []\"  , end =\" \")\n",
    "        for value in ce[key]:\n",
    "            print(value.name , end =\" \")\n",
    "    print(\" \")\n",
    "    \n",
    "    \n",
    "L = [Tft(), Spiteful(), Mem(0,1,\"cCD\"),  Mem(1,1,\"cCDDD\"), Periodic(\"CDC\") ]\n",
    "ce = classesEquiv(L, [Periodic('CDCCDDC'), Periodic('DDCDCDD')], 10)\n",
    "printCe(ce)\n",
    "print(\"Simplified set size : \" + str(len(ce.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On rappelle que la qualité de cette simplification dépend très fortement de la qualité de la liste de référence. On le constate aisément en tentant de simplifier `mem(1,2)` face à une liste de plus en plus grande de stratégies de référence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mem(1,2) contains 1024 strategies\n",
    "\n",
    "# Without any opponent, they are all considered equivalent.\n",
    "ce = classesEquiv(getMem(1,2), [], 10)\n",
    "print(len(ce.keys()))\n",
    "\n",
    "# Comparing with simply ALL_C , only 9 different strategies are available\n",
    "ce = classesEquiv(getMem(1,2), [Periodic('C')], 10)\n",
    "print(len(ce.keys()))\n",
    "\n",
    "# We're gradually strengthening the test\n",
    "ce = classesEquiv(getMem(1,2), [Periodic('C'), Periodic('CDCCDDC'), Periodic('DDCDCDD')], 10)\n",
    "print(len(ce.keys()))\n",
    "\n",
    "ce = classesEquiv(getMem(1,2), [Periodic('C'), Periodic('CDCCDDC'), Periodic('DDCDCDD'),Gradual()], 10)\n",
    "print(len(ce.keys()))\n",
    "\n",
    "# So? How large is this simplified set really?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut encore renforcer le test en commençant par faire jouer toutes les stratégies de l'ensemble à tester entre elles. Bien évidemment si des stratégies sont identiques, elles doivent avoir le même score dans ce tournoi. On peut donc se contenter de tester les équivalences sur les ensembles de stratégies qui obtiennent en Tournoi un score identique. Rajouter cette équivalence des scores renforce encore un peu plus notre test.\n",
    "Bien évidemment ceci se fait au détriment du temps de calcul.\n",
    "La fonction `simplify` effectue ce travail. Elle fonctionne comme précédemment mais démarre par un tournoi afin d'identifier les paquets de stratégies ayant le même score. On concatène ensuite chacun des dictionnaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(l, opponents, length):\n",
    "    scores = dict()\n",
    "    t = Tournament(g, opponents + l, length)\n",
    "    t.run()\n",
    "    res = t.matrix['Total']\n",
    "    for strat in l : \n",
    "        score = res[strat.name]\n",
    "        if score not in scores :\n",
    "            scores[score] = [strat]\n",
    "        else : \n",
    "            scores[score] += [strat]\n",
    "    \n",
    "    d = dict()\n",
    "    for item in scores.values():\n",
    "        if len(item) > 1 :\n",
    "            res = classesEquiv(item, opponents, length)\n",
    "            for it in res.keys():\n",
    "                if len(res[it]) > 0 :\n",
    "                    d[it] = res[it]\n",
    "        else : \n",
    "            d[item[0]] = []\n",
    "    return d\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "strats = simplify(getMem(1,2), [Periodic('C'), Periodic('CDCCDDC'), Periodic('DDCDCDD'),Gradual()], 10)\n",
    "print(\"Simplified set size : \" + str(len(strats)))\n",
    "\n",
    "# RECORD BROKEN! 820... but this test remains undecidable, it is nevertheless subject to a doubt... \n",
    "        \n",
    "printCe(strats)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tableau de synthèse\n",
    "\n",
    "Etant donnée une base de comparaison, réaliser un tableau contenant pour chacune des classes de Memory classiques, la synthèse des tailles obtenues après simplication via ClassesEquiv et simplification via Simplify "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base  = [Periodic('CDCCDDC'), Periodic('DDCDCDD'),Gradual()]\n",
    "\n",
    "Mem01 = getMem(0,1)\n",
    "Mem10 = getMem(1,0)\n",
    "Mem11 = getMem(1,1)\n",
    "Mem12 = getMem(1,2)\n",
    "Mem21 = getMem(2,1)\n",
    "\n",
    "ce01 = classesEquiv(Mem01, base, 10)\n",
    "ce10 = classesEquiv(Mem10, base, 10)\n",
    "ce11 = classesEquiv(Mem11, base, 10)\n",
    "ce12 = classesEquiv(Mem12, base, 10)\n",
    "ce21 = classesEquiv(Mem21, base, 10)\n",
    "\n",
    "simp01 = simplify(Mem01, base, 10)\n",
    "simp10 = simplify(Mem10, base, 10)\n",
    "simp11 = simplify(Mem11, base, 10)\n",
    "simp12 = simplify(Mem12, base, 10)\n",
    "simp21 = simplify(Mem21, base, 10)\n",
    "\n",
    "# idem avec simplify\n",
    "\n",
    "tab = pd.DataFrame(\n",
    "        np.nan, [\"Mem 0 1\",\"Mem 1 0\",\"Mem 1 1\", \"Mem 1 2\", \"Mem 2 1\"], [\"All strategies\", \"After classesEquiv\",\"After simplify\"]\n",
    "    )\n",
    "tab.at[\"Mem 0 1\", \"All strategies\" ] = len(Mem01)\n",
    "tab.at[\"Mem 1 0\", \"All strategies\" ] = len(Mem10)\n",
    "tab.at[\"Mem 1 1\", \"All strategies\" ] = len(Mem11)\n",
    "tab.at[\"Mem 1 2\", \"All strategies\" ] = len(Mem12)\n",
    "tab.at[\"Mem 2 1\", \"All strategies\" ] = len(Mem21)\n",
    "tab.at[\"Mem 0 1\", \"After classesEquiv\" ] = len(ce01.keys())\n",
    "tab.at[\"Mem 1 0\", \"After classesEquiv\" ] = len(ce10.keys())\n",
    "tab.at[\"Mem 1 1\", \"After classesEquiv\" ] = len(ce11.keys())\n",
    "tab.at[\"Mem 1 2\", \"After classesEquiv\" ] = len(ce12.keys())\n",
    "tab.at[\"Mem 2 1\", \"After classesEquiv\" ] = len(ce21.keys())\n",
    "tab.at[\"Mem 0 1\", \"After simplify\" ] = len(simp01)\n",
    "tab.at[\"Mem 1 0\", \"After simplify\" ] = len(simp10)\n",
    "tab.at[\"Mem 1 1\", \"After simplify\" ] = len(simp11)\n",
    "tab.at[\"Mem 1 2\", \"After simplify\" ] = len(simp12.keys())\n",
    "tab.at[\"Mem 2 1\", \"After simplify\" ] = len(simp21)\n",
    "tab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petite vérification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simpl = simplify(getMem(1,1), [Periodic('CDCCDDC'), Periodic('DDCDCDD')], 10)\n",
    "print(len(simpl))\n",
    "e1 = Ecological(g, getMem(1,1))\n",
    "e1.run()\n",
    "\n",
    "evol=e1.historic\n",
    "nbSurvivors = len(evol.iloc[-1][evol.iloc[-1]>0])\n",
    "e1.drawPlot(None,nbSurvivors)\n",
    "\n",
    "\n",
    "e2 = Ecological(g, list(simpl.keys()))\n",
    "e2.run()\n",
    "\n",
    "evol=e2.historic\n",
    "nbSurvivors = len(evol.iloc[-1][evol.iloc[-1]>0])\n",
    "e2.drawPlot(None,nbSurvivors)\n",
    "\n",
    "\n",
    "\n",
    "# On constate qu'avec mem(1,1) on passe de 32 stratégies à 26 stratégies\n",
    "# On constate aussi que la compétition des simplifiées donne le même classement excepté \n",
    "# le fait que ALL_C survit dans la version simplifiée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trie_Mem(strategies):\n",
    "    strategies.sort(key=lambda x: x.genome)\n",
    "    return strategies\n",
    "\n",
    "\n",
    "sortMem11 = trie_Mem(getMem(1,1))\n",
    "for s in sortMem11:\n",
    "    print(s.genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_simplify(l, opponents, length, batchSize):\n",
    "    size = len(l)\n",
    "    strats = []\n",
    "    simplified = set()\n",
    "    for i in range(int(size/batchSize)):\n",
    "        strats += l[i * batchSize : (i+1) * batchSize]\n",
    "        res = simplify(strats, opponents, length)\n",
    "        print(\"{} strategies deleted\".format(len(strats) - len(res)))\n",
    "        for strat in res.keys() :\n",
    "            simplified.add(strat)\n",
    "        strats = list(simplified)\n",
    "    return simplified\n",
    "\n",
    "\n",
    "        \n",
    "print(rec_simplify([Tft(), Spiteful(), Mem(0,1,\"cCD\"),  Mem(1,1,\"cCDDD\"), Periodic(\"CDC\"), Periodic('C') ], [Periodic('CCD'), Periodic('DDC')] , 10, 2))\n",
    "print(\" \")\n",
    "sortMem12 = trie_Mem(getMem(1,2))\n",
    "rec_simplify(sortMem12, [Periodic('CCD'), Periodic('DDC')] , 10, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dilemme spatial (en cours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Input variables for the board\n",
    "boardsize = 10   # board will be X by X where X = boardsize\n",
    "my_board = np.empty((boardsize, boardsize), dtype=float)\n",
    "\n",
    "\n",
    "# 0 : cooperator\n",
    "# 1 : new cooperator\n",
    "# 2 : defector   \n",
    "# 3 : new defector\n",
    "\n",
    "\n",
    "# Some helper functions\n",
    "def init_strategies():\n",
    "    strategies = np.zeros((boardsize, boardsize), dtype=object)\n",
    "    for i in range(boardsize) :\n",
    "        for j in range(boardsize):\n",
    "            strategies[i, j] = 0\n",
    "    strategies[5, 5] = 2\n",
    "    return strategies\n",
    "    \n",
    "# Initialize the board with starting positions\n",
    "# def strategies_to_board(strategies):\n",
    "#     for i in range(boardsize) :\n",
    "#         for j in range(boardsize) :\n",
    "#             if strategies[i, j] == \"C\":\n",
    "#                 my_board[i , j] = 0\n",
    "#             else : \n",
    "#                 my_board[i, j] = 1\n",
    "#     #print(\"-------------------------\")\n",
    "#     #print(strategies)\n",
    "#     #print(my_board)\n",
    "#     #print(\"--------------------------------\")\"\n",
    "#     return my_board\n",
    "    \n",
    "\n",
    "# https://github.com/evoplex/model-prisonersDilemma\n",
    "def update_strategies():\n",
    "    scores = play()\n",
    "    strategies = np.copy(update(scores))\n",
    "    #print(strategies)\n",
    "    return strategies\n",
    "\n",
    "def play():\n",
    "    scores = np.zeros((boardsize, boardsize))\n",
    "    for i in range(boardsize):\n",
    "        for j in range(boardsize):\n",
    "            score = 0\n",
    "            #cpt = 0\n",
    "            score += getScore(strategies, i, j, i, j)\n",
    "            if i >= 0 and j >= 0:\n",
    "                score += getScore(strategies, i, j, i-1, j-1)\n",
    "                #cpt += 1\n",
    "            if j >= 0:\n",
    "                score += getScore(strategies, i, j, i, j-1)\n",
    "                #cpt += 1\n",
    "            if i >= 0 :\n",
    "                score += getScore(strategies, i, j, i-1, j)\n",
    "                #cpt += 1\n",
    "            if i < boardsize - 1 and j < boardsize - 1 :\n",
    "                score += getScore(strategies, i, j, i+1, j+1)\n",
    "                #cpt += 1\n",
    "            if i < boardsize - 1 :\n",
    "                score += getScore(strategies, i, j, i+1, j)\n",
    "                #cpt += 1\n",
    "            if j < boardsize -1 :\n",
    "                score += getScore(strategies, i, j, i, j+1)\n",
    "                #cpt += 1\n",
    "            if i < boardsize - 1 and j >= 0:\n",
    "                score += getScore(strategies, i, j, i+1, j-1)\n",
    "                #cpt += 1\n",
    "            if i >= 0 and j < boardsize - 1 :\n",
    "                score += getScore(strategies, i, j, i-1, j+1)\n",
    "                #cpt += 1\n",
    "            scores[i][j] = score\n",
    "    #print(scores)\n",
    "    return scores\n",
    "\n",
    "def update(scores):\n",
    "    #print(scores)\n",
    "    new_strategies = np.zeros((boardsize, boardsize), dtype=object)\n",
    "    for i in range(boardsize):\n",
    "        for j in range(boardsize):\n",
    "            best = scores[i][j]\n",
    "            ind_i = i \n",
    "            ind_j = j\n",
    "            if i >= 0 and j >= 0:\n",
    "                if scores[i-1][j-1] > best :\n",
    "                    best = scores[i-1][j-1]\n",
    "                    ind_i = i - 1\n",
    "                    ind_j = j - 1\n",
    "            if j >= 0:\n",
    "                if scores[i][j-1] > best :\n",
    "                    best = scores[i][j-1]\n",
    "                    ind_i = i \n",
    "                    ind_j = j - 1\n",
    "            if i >= 0 :\n",
    "                if scores[i-1][j] > best :\n",
    "                    best = scores[i-1][j]\n",
    "                    ind_i = i - 1\n",
    "                    ind_j = j \n",
    "            if i < boardsize - 1  and j < boardsize - 1 :\n",
    "                if scores[i+1][j+1] > best :\n",
    "                    best = scores[i+1][j+1]\n",
    "                    ind_i = i + 1\n",
    "                    ind_j = j + 1\n",
    "            if i < boardsize - 1:\n",
    "                if scores[i+1][j] > best :\n",
    "                    best = scores[i+1][j]\n",
    "                    ind_i = i + 1\n",
    "                    ind_j = j \n",
    "            if j < boardsize - 1:\n",
    "                if scores[i][j+1] > best :\n",
    "                    best = scores[i][j+1]\n",
    "                    ind_i = i \n",
    "                    ind_j = j + 1\n",
    "            if i < boardsize - 1 and j >= 0:\n",
    "                if scores[i+1][j-1] > best :\n",
    "                    best = scores[i+1][j-1]\n",
    "                    ind_i = i + 1\n",
    "                    ind_j = j - 1\n",
    "            if i >= 0 and j < boardsize - 1:\n",
    "                if scores[i-1][j+1] > best :\n",
    "                    best = scores[i-1][j+1]\n",
    "                    ind_i = i - 1\n",
    "                    ind_j = j + 1\n",
    "\n",
    "                    \n",
    "            # new cooperator\n",
    "            if (strategies[i][j] > 1) and (strategies[ind_i][ind_j] < 2):\n",
    "                new_strategies[i][j] = 1\n",
    "            # new defector\n",
    "            if (strategies[i][j] < 2) and (strategies[ind_i][ind_j] > 1):\n",
    "                new_strategies[i][j] = 3\n",
    "            else : \n",
    "                new_strategies[i][j] = strategies[ind_i][ind_j]\n",
    "    return new_strategies\n",
    "            \n",
    "\n",
    "def getScore(strategies, i, j, k, l):\n",
    "    s1 = strategies[i][j]\n",
    "    s2 = strategies[k][l]\n",
    "    res = binarize(s1) * 2 + binarize(s2)\n",
    "    if res == 0:# CC \n",
    "        return 1\n",
    "    elif res == 1 :# CD \n",
    "        return 0\n",
    "    elif res == 2:# DC \n",
    "        return 1.9\n",
    "    else :  # DD \n",
    "        return 0\n",
    "    \n",
    "def binarize(strategy):\n",
    "    if strategy < 2:\n",
    "        return strategy\n",
    "    else :\n",
    "        return strategy - 2\n",
    "\n",
    "\n",
    "# def update_board(my_board):\n",
    "#     strategies = np.copy(update_strategies())\n",
    "#     print(strategies)\n",
    "#     my_board = np.copy(strategies_to_board(strategies))\n",
    "#     print(my_board)\n",
    "#     return my_board\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the board\n",
    "strategies = init_strategies()\n",
    "print(strategies)\n",
    "strategies = np.copy(update_strategies())\n",
    "print(strategies)\n",
    "# my_board = strategies_to_board(strategies)\n",
    "\n",
    "##### Animate the board #####\n",
    "# This will throw an error the first time you run the code, but the program will run properly if you\n",
    "# execute the cell again (there is an error with the animation package that I cannot seem to get rid of)\n",
    "\n",
    "# # Required line for plotting the animation\n",
    "# %matplotlib notebook\n",
    "# # Initialize the plot of the board that will be used for animation\n",
    "# fig = plt.gcf()\n",
    "# # Show first image - which is the initial board\n",
    "# im = plt.imshow(my_board)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# # Helper function that updates the board and returns a new image of\n",
    "# # the updated board animate is the function that FuncAnimation calls\n",
    "# def animate(frame):\n",
    "#     im.set_data(update_board(my_board))\n",
    "#     return im,\n",
    "\n",
    "# # This line creates the animation\n",
    "# anim = animation.FuncAnimation(fig, animate, interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie\n",
    "- Evolutionary games and spatial chaos, Martin A. Nowak & Robert M. May "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
